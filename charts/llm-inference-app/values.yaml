nameOverride: ""
fullnameOverride: ""

# Deployment
llm:
  modelHFName: ""
  modelRevision: ""
  tokenizerHFName: ""
  tokenizerRevision: ""

model:
  modelHFName: ""
  modelRevision: ""
  tokenizerHFName: ""
  tokenizerRevision: ""

serverExtraArgs: []

replicaCount: 1

image:
  repository: quay.io/opendatahub/vllm
  pullPolicy: IfNotPresent
  tag: stable-rocm-9ac4882
  imagePullSecrets: []

resources: {}

healthChecksDelay: 60

volumesManage: false
PVCVolumes: []

  # - pvcName: huggingface-cache
  #   autocreate: false
  #   accessMode: ReadWriteOnce
  #   storageClassName: ""
  #   storage: 300Gi
  #   mountPath: /root/.cache/huggingface
  #   mountReadOnly: false
  #   volumeSubPath: "llm-cache"

cache:
  enabled: true
  sizeLimit: 100Gi

env:
  HUGGING_FACE_HUB_TOKEN: ""

podAnnotations: {}

nodeSelector: {}

tolerations:
  - key: platform.neuromation.io/job
    operator: Exists
    effect: NoSchedule
  - key: amd.com/gpu
    operator: Exists
    effect: NoSchedule

affinity: {}

priorityClassName: ""

# Model download hook
modelDownload:
  # hook is WIP, use initEnabled for now
  hookEnabled: false
  initEnabled: true
  image:
    repository: huggingface/downloader
    tag: 0.17.3
    pullPolicy: IfNotPresent
  resources: {}

# Service
service:
  port: 8000

# Ingress
ingress:
  enabled: false
  clusterName: ""

preset_name: ""
